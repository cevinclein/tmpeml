Running exercise04_template.py
0.0%0.0%0.1%0.1%0.1%0.1%0.1%0.2%0.2%0.2%0.2%0.2%0.2%0.3%0.3%0.3%0.3%0.3%0.4%0.4%0.4%0.4%0.4%0.5%0.5%0.5%0.5%0.5%0.6%0.6%0.6%0.6%0.6%0.7%0.7%0.7%0.7%0.7%0.7%0.8%0.8%0.8%0.8%0.8%0.9%0.9%0.9%0.9%0.9%1.0%1.0%1.0%1.0%1.0%1.1%1.1%1.1%1.1%1.1%1.2%1.2%1.2%1.2%1.2%1.2%1.3%1.3%1.3%1.3%1.3%1.4%1.4%1.4%1.4%1.4%1.5%1.5%1.5%1.5%1.5%1.6%1.6%1.6%1.6%1.6%1.7%1.7%1.7%1.7%1.7%1.7%1.8%1.8%1.8%1.8%1.8%1.9%1.9%1.9%1.9%1.9%2.0%2.0%2.0%2.0%2.0%2.1%2.1%2.1%2.1%2.1%2.2%2.2%2.2%2.2%2.2%2.2%2.3%2.3%2.3%2.3%2.3%2.4%2.4%2.4%2.4%2.4%2.5%2.5%2.5%2.5%2.5%2.6%2.6%2.6%2.6%2.6%2.7%2.7%2.7%2.7%2.7%2.7%2.8%2.8%2.8%2.8%2.8%2.9%2.9%2.9%2.9%2.9%3.0%3.0%3.0%3.0%3.0%3.1%3.1%3.1%3.1%3.1%3.2%3.2%3.2%3.2%3.2%3.2%3.3%3.3%3.3%3.3%3.3%3.4%3.4%3.4%3.4%3.4%3.5%3.5%3.5%3.5%3.5%3.6%3.6%3.6%3.6%3.6%3.7%3.7%3.7%3.7%3.7%3.7%3.8%3.8%3.8%3.8%3.8%3.9%3.9%3.9%3.9%3.9%4.0%4.0%4.0%4.0%4.0%4.1%4.1%4.1%4.1%4.1%4.2%4.2%4.2%4.2%4.2%4.2%4.3%4.3%4.3%4.3%4.3%4.4%4.4%4.4%4.4%4.4%4.5%4.5%4.5%4.5%4.5%4.6%4.6%4.6%4.6%4.6%4.7%4.7%4.7%4.7%4.7%4.7%4.8%4.8%4.8%4.8%4.8%4.9%4.9%4.9%4.9%4.9%5.0%5.0%5.0%5.0%5.0%5.1%5.1%5.1%5.1%5.1%5.2%5.2%5.2%5.2%5.2%5.2%5.3%5.3%5.3%5.3%5.3%5.4%5.4%5.4%5.4%5.4%5.5%5.5%5.5%5.5%5.5%5.6%5.6%5.6%5.6%5.6%5.7%5.7%5.7%5.7%5.7%5.7%5.8%5.8%5.8%5.8%5.8%5.9%5.9%5.9%5.9%5.9%6.0%6.0%6.0%6.0%6.0%6.1%6.1%6.1%6.1%6.1%6.2%6.2%6.2%6.2%6.2%6.2%6.3%6.3%6.3%6.3%6.3%6.4%6.4%6.4%6.4%6.4%6.5%6.5%6.5%6.5%6.5%6.6%6.6%6.6%6.6%6.6%6.6%6.7%6.7%6.7%6.7%6.7%6.8%6.8%6.8%6.8%6.8%6.9%6.9%6.9%6.9%6.9%7.0%7.0%7.0%7.0%7.0%7.1%7.1%7.1%7.1%7.1%7.1%7.2%7.2%7.2%7.2%7.2%7.3%7.3%7.3%7.3%7.3%7.4%7.4%7.4%7.4%7.4%7.5%7.5%7.5%7.5%7.5%7.6%7.6%7.6%7.6%7.6%7.6%7.7%7.7%7.7%7.7%7.7%7.8%7.8%7.8%7.8%7.8%7.9%7.9%7.9%7.9%7.9%8.0%8.0%8.0%8.0%8.0%8.1%8.1%8.1%8.1%8.1%8.1%8.2%8.2%8.2%8.2%8.2%8.3%8.3%8.3%8.3%8.3%8.4%8.4%8.4%8.4%8.4%8.5%8.5%8.5%8.5%8.5%8.6%8.6%8.6%8.6%8.6%8.6%8.7%8.7%8.7%8.7%8.7%8.8%8.8%8.8%8.8%8.8%8.9%8.9%8.9%8.9%8.9%9.0%9.0%9.0%9.0%9.0%9.1%9.1%9.1%9.1%9.1%9.1%9.2%9.2%9.2%9.2%9.2%9.3%9.3%9.3%9.3%9.3%9.4%9.4%9.4%9.4%9.4%9.5%9.5%9.5%9.5%9.5%9.6%9.6%9.6%9.6%9.6%9.6%9.7%9.7%9.7%9.7%9.7%9.8%9.8%9.8%9.8%9.8%9.9%9.9%9.9%9.9%9.9%10.0%10.0%10.0%10.0%10.0%10.1%10.1%10.1%10.1%10.1%10.1%10.2%10.2%10.2%10.2%10.2%10.3%10.3%10.3%10.3%10.3%10.4%10.4%10.4%10.4%10.4%10.5%10.5%10.5%10.5%10.5%10.6%10.6%10.6%10.6%10.6%10.6%10.7%10.7%10.7%10.7%10.7%10.8%10.8%10.8%10.8%10.8%10.9%10.9%10.9%10.9%10.9%11.0%11.0%11.0%11.0%11.0%11.1%11.1%11.1%11.1%11.1%11.1%11.2%11.2%11.2%11.2%11.2%11.3%11.3%11.3%11.3%11.3%11.4%11.4%11.4%11.4%11.4%11.5%11.5%11.5%11.5%11.5%11.6%11.6%11.6%11.6%11.6%11.6%11.7%11.7%11.7%11.7%11.7%11.8%11.8%11.8%11.8%11.8%11.9%11.9%11.9%11.9%11.9%12.0%12.0%12.0%12.0%12.0%12.1%12.1%12.1%12.1%12.1%12.1%12.2%12.2%12.2%12.2%12.2%12.3%12.3%12.3%12.3%12.3%12.4%12.4%12.4%12.4%12.4%12.5%12.5%12.5%12.5%12.5%12.5%12.6%12.6%12.6%12.6%12.6%12.7%12.7%12.7%12.7%12.7%12.8%12.8%12.8%12.8%12.8%12.9%12.9%12.9%12.9%12.9%13.0%13.0%13.0%13.0%13.0%13.0%13.1%13.1%13.1%13.1%13.1%13.2%13.2%13.2%13.2%13.2%13.3%13.3%13.3%13.3%13.3%13.4%13.4%13.4%13.4%13.4%13.5%13.5%13.5%13.5%13.5%13.5%13.6%13.6%13.6%13.6%13.6%13.7%13.7%13.7%13.7%13.7%13.8%13.8%13.8%13.8%13.8%13.9%13.9%13.9%13.9%13.9%14.0%14.0%14.0%14.0%14.0%14.0%14.1%14.1%14.1%14.1%14.1%14.2%14.2%14.2%14.2%14.2%14.3%14.3%14.3%14.3%14.3%14.4%14.4%14.4%14.4%14.4%14.5%14.5%14.5%14.5%14.5%14.5%14.6%14.6%14.6%14.6%14.6%14.7%14.7%14.7%14.7%14.7%14.8%14.8%14.8%14.8%14.8%14.9%14.9%14.9%14.9%14.9%15.0%15.0%15.0%15.0%15.0%15.0%15.1%15.1%15.1%15.1%15.1%15.2%15.2%15.2%15.2%15.2%15.3%15.3%15.3%15.3%15.3%15.4%15.4%15.4%15.4%15.4%15.5%15.5%15.5%15.5%15.5%15.5%15.6%15.6%15.6%15.6%15.6%15.7%15.7%15.7%15.7%15.7%15.8%15.8%15.8%15.8%15.8%15.9%15.9%15.9%15.9%15.9%16.0%16.0%16.0%16.0%16.0%16.0%16.1%16.1%16.1%16.1%16.1%16.2%16.2%16.2%16.2%16.2%16.3%16.3%16.3%16.3%16.3%16.4%16.4%16.4%16.4%16.4%16.5%16.5%16.5%16.5%16.5%16.5%16.6%16.6%16.6%16.6%16.6%16.7%16.7%16.7%16.7%16.7%16.8%16.8%16.8%16.8%16.8%16.9%16.9%16.9%16.9%16.9%17.0%17.0%17.0%17.0%17.0%17.0%17.1%17.1%17.1%17.1%17.1%17.2%17.2%17.2%17.2%17.2%17.3%17.3%17.3%17.3%17.3%17.4%17.4%17.4%17.4%17.4%17.5%17.5%17.5%17.5%17.5%17.5%17.6%17.6%17.6%17.6%17.6%17.7%17.7%17.7%17.7%17.7%17.8%17.8%17.8%17.8%17.8%17.9%17.9%17.9%17.9%17.9%18.0%18.0%18.0%18.0%18.0%18.0%18.1%18.1%18.1%18.1%18.1%18.2%18.2%18.2%18.2%18.2%18.3%18.3%18.3%18.3%18.3%18.4%18.4%18.4%18.4%18.4%18.5%18.5%18.5%18.5%18.5%18.5%18.6%18.6%18.6%18.6%18.6%18.7%18.7%18.7%18.7%18.7%18.8%18.8%18.8%18.8%18.8%18.9%18.9%18.9%18.9%18.9%18.9%19.0%19.0%19.0%19.0%19.0%19.1%19.1%19.1%19.1%19.1%19.2%19.2%19.2%19.2%19.2%19.3%19.3%19.3%19.3%19.3%19.4%19.4%19.4%19.4%19.4%19.4%19.5%19.5%19.5%19.5%19.5%19.6%19.6%19.6%19.6%19.6%19.7%19.7%19.7%19.7%19.7%19.8%19.8%19.8%19.8%19.8%19.9%19.9%19.9%19.9%19.9%19.9%20.0%20.0%20.0%20.0%20.0%20.1%20.1%20.1%20.1%20.1%20.2%20.2%20.2%20.2%20.2%20.3%20.3%20.3%20.3%20.3%20.4%20.4%20.4%20.4%20.4%20.4%20.5%20.5%20.5%20.5%20.5%20.6%20.6%20.6%20.6%20.6%20.7%20.7%20.7%20.7%20.7%20.8%20.8%20.8%20.8%20.8%20.9%20.9%20.9%20.9%20.9%20.9%21.0%21.0%21.0%21.0%21.0%21.1%21.1%21.1%21.1%21.1%21.2%21.2%21.2%21.2%21.2%21.3%21.3%21.3%21.3%21.3%21.4%21.4%21.4%21.4%21.4%21.4%21.5%21.5%21.5%21.5%21.5%21.6%21.6%21.6%21.6%21.6%21.7%21.7%21.7%21.7%21.7%21.8%21.8%21.8%21.8%21.8%21.9%21.9%21.9%21.9%21.9%21.9%22.0%22.0%22.0%22.0%22.0%22.1%22.1%22.1%22.1%22.1%22.2%22.2%22.2%22.2%22.2%22.3%22.3%22.3%22.3%22.3%22.4%22.4%22.4%22.4%22.4%22.4%22.5%22.5%22.5%22.5%22.5%22.6%22.6%22.6%22.6%22.6%22.7%22.7%22.7%22.7%22.7%22.8%22.8%22.8%22.8%22.8%22.9%22.9%22.9%22.9%22.9%22.9%23.0%23.0%23.0%23.0%23.0%23.1%23.1%23.1%23.1%23.1%23.2%23.2%23.2%23.2%23.2%23.3%23.3%23.3%23.3%23.3%23.4%23.4%23.4%23.4%23.4%23.4%23.5%23.5%23.5%23.5%23.5%23.6%23.6%23.6%23.6%23.6%23.7%23.7%23.7%23.7%23.7%23.8%23.8%23.8%23.8%23.8%23.9%23.9%23.9%23.9%23.9%23.9%24.0%24.0%24.0%24.0%24.0%24.1%24.1%24.1%24.1%24.1%24.2%24.2%24.2%24.2%24.2%24.3%24.3%24.3%24.3%24.3%24.4%24.4%24.4%24.4%24.4%24.4%24.5%24.5%24.5%24.5%24.5%24.6%24.6%24.6%24.6%24.6%24.7%24.7%24.7%24.7%24.7%24.8%24.8%24.8%24.8%24.8%24.9%24.9%24.9%24.9%24.9%24.9%25.0%25.0%25.0%25.0%25.0%25.1%25.1%25.1%25.1%25.1%25.2%25.2%25.2%25.2%25.2%25.3%25.3%25.3%25.3%25.3%25.3%25.4%25.4%25.4%25.4%25.4%25.5%25.5%25.5%25.5%25.5%25.6%25.6%25.6%25.6%25.6%25.7%25.7%25.7%25.7%25.7%25.8%25.8%25.8%25.8%25.8%25.8%25.9%25.9%25.9%25.9%25.9%26.0%26.0%26.0%26.0%26.0%26.1%26.1%26.1%26.1%26.1%26.2%26.2%26.2%26.2%26.2%26.3%26.3%26.3%26.3%26.3%26.3%26.4%26.4%26.4%26.4%26.4%26.5%26.5%26.5%26.5%26.5%26.6%26.6%26.6%26.6%26.6%26.7%26.7%26.7%26.7%26.7%26.8%26.8%26.8%26.8%26.8%26.8%26.9%26.9%26.9%26.9%26.9%27.0%27.0%27.0%27.0%27.0%27.1%27.1%27.1%27.1%27.1%27.2%27.2%27.2%27.2%27.2%27.3%27.3%27.3%27.3%27.3%27.3%27.4%27.4%27.4%27.4%27.4%27.5%27.5%27.5%27.5%27.5%27.6%27.6%27.6%27.6%27.6%27.7%27.7%27.7%27.7%27.7%27.8%27.8%27.8%27.8%27.8%27.8%27.9%27.9%27.9%27.9%27.9%28.0%28.0%28.0%28.0%28.0%28.1%28.1%28.1%28.1%28.1%28.2%28.2%28.2%28.2%28.2%28.3%28.3%28.3%28.3%28.3%28.3%28.4%28.4%28.4%28.4%28.4%28.5%28.5%28.5%28.5%28.5%28.6%28.6%28.6%28.6%28.6%28.7%28.7%28.7%28.7%28.7%28.8%28.8%28.8%28.8%28.8%28.8%28.9%28.9%28.9%28.9%28.9%29.0%29.0%29.0%29.0%29.0%29.1%29.1%29.1%29.1%29.1%29.2%29.2%29.2%29.2%29.2%29.3%29.3%29.3%29.3%29.3%29.3%29.4%29.4%29.4%29.4%29.4%29.5%29.5%29.5%29.5%29.5%29.6%29.6%29.6%29.6%29.6%29.7%29.7%29.7%29.7%29.7%29.8%29.8%29.8%29.8%29.8%29.8%29.9%29.9%29.9%29.9%29.9%30.0%30.0%30.0%30.0%30.0%30.1%30.1%30.1%30.1%30.1%30.2%30.2%30.2%30.2%30.2%30.3%30.3%30.3%30.3%30.3%30.3%30.4%30.4%30.4%30.4%30.4%30.5%30.5%30.5%30.5%30.5%30.6%30.6%30.6%30.6%30.6%30.7%30.7%30.7%30.7%30.7%30.8%30.8%30.8%30.8%30.8%30.8%30.9%30.9%30.9%30.9%30.9%31.0%31.0%31.0%31.0%31.0%31.1%31.1%31.1%31.1%31.1%31.2%31.2%31.2%31.2%31.2%31.3%31.3%31.3%31.3%31.3%31.3%31.4%31.4%31.4%31.4%31.4%31.5%31.5%31.5%31.5%31.5%31.6%31.6%31.6%31.6%31.6%31.7%31.7%31.7%31.7%31.7%31.7%31.8%31.8%31.8%31.8%31.8%31.9%31.9%31.9%31.9%31.9%32.0%32.0%32.0%32.0%32.0%32.1%32.1%32.1%32.1%32.1%32.2%32.2%32.2%32.2%32.2%32.2%32.3%32.3%32.3%32.3%32.3%32.4%32.4%32.4%32.4%32.4%32.5%32.5%32.5%32.5%32.5%32.6%32.6%32.6%32.6%32.6%32.7%32.7%32.7%32.7%32.7%32.7%32.8%32.8%32.8%32.8%32.8%32.9%32.9%32.9%32.9%32.9%33.0%33.0%33.0%33.0%33.0%33.1%33.1%33.1%33.1%33.1%33.2%33.2%33.2%33.2%33.2%33.2%33.3%33.3%33.3%33.3%33.3%33.4%33.4%33.4%33.4%33.4%33.5%33.5%33.5%33.5%33.5%33.6%33.6%33.6%33.6%33.6%33.7%33.7%33.7%33.7%33.7%33.7%33.8%33.8%33.8%33.8%33.8%33.9%33.9%33.9%33.9%33.9%34.0%34.0%34.0%34.0%34.0%34.1%34.1%34.1%34.1%34.1%34.2%34.2%34.2%34.2%34.2%34.2%34.3%34.3%34.3%34.3%34.3%34.4%34.4%34.4%34.4%34.4%34.5%34.5%34.5%34.5%34.5%34.6%34.6%34.6%34.6%34.6%34.7%34.7%34.7%34.7%34.7%34.7%34.8%34.8%34.8%34.8%34.8%34.9%34.9%34.9%34.9%34.9%35.0%35.0%35.0%35.0%35.0%35.1%35.1%35.1%35.1%35.1%35.2%35.2%35.2%35.2%35.2%35.2%35.3%35.3%35.3%35.3%35.3%35.4%35.4%35.4%35.4%35.4%35.5%35.5%35.5%35.5%35.5%35.6%35.6%35.6%35.6%35.6%35.7%35.7%35.7%35.7%35.7%35.7%35.8%35.8%35.8%35.8%35.8%35.9%35.9%35.9%35.9%35.9%36.0%36.0%36.0%36.0%36.0%36.1%36.1%36.1%36.1%36.1%36.2%36.2%36.2%36.2%36.2%36.2%36.3%36.3%36.3%36.3%36.3%36.4%36.4%36.4%36.4%36.4%36.5%36.5%36.5%36.5%36.5%36.6%36.6%36.6%36.6%36.6%36.7%36.7%36.7%36.7%36.7%36.7%36.8%36.8%36.8%36.8%36.8%36.9%36.9%36.9%36.9%36.9%37.0%37.0%37.0%37.0%37.0%37.1%37.1%37.1%37.1%37.1%37.2%37.2%37.2%37.2%37.2%37.2%37.3%37.3%37.3%37.3%37.3%37.4%37.4%37.4%37.4%37.4%37.5%37.5%37.5%37.5%37.5%37.6%37.6%37.6%37.6%37.6%37.6%37.7%37.7%37.7%37.7%37.7%37.8%37.8%37.8%37.8%37.8%37.9%37.9%37.9%37.9%37.9%38.0%38.0%38.0%38.0%38.0%38.1%38.1%38.1%38.1%38.1%38.1%38.2%38.2%38.2%38.2%38.2%38.3%38.3%38.3%38.3%38.3%38.4%38.4%38.4%38.4%38.4%38.5%38.5%38.5%38.5%38.5%38.6%38.6%38.6%38.6%38.6%38.6%38.7%38.7%38.7%38.7%38.7%38.8%38.8%38.8%38.8%38.8%38.9%38.9%38.9%38.9%38.9%39.0%39.0%39.0%39.0%39.0%39.1%39.1%39.1%39.1%39.1%39.1%39.2%39.2%39.2%39.2%39.2%39.3%39.3%39.3%39.3%39.3%39.4%39.4%39.4%39.4%39.4%39.5%39.5%39.5%39.5%39.5%39.6%39.6%39.6%39.6%39.6%39.6%39.7%39.7%39.7%39.7%39.7%39.8%39.8%39.8%39.8%39.8%39.9%39.9%39.9%39.9%39.9%40.0%40.0%40.0%40.0%40.0%40.1%40.1%40.1%40.1%40.1%40.1%40.2%40.2%40.2%40.2%40.2%40.3%40.3%40.3%40.3%40.3%40.4%40.4%40.4%40.4%40.4%40.5%40.5%40.5%40.5%40.5%40.6%40.6%40.6%40.6%40.6%40.6%40.7%40.7%40.7%40.7%40.7%40.8%40.8%40.8%40.8%40.8%40.9%40.9%40.9%40.9%40.9%41.0%41.0%41.0%41.0%41.0%41.1%41.1%41.1%41.1%41.1%41.1%41.2%41.2%41.2%41.2%41.2%41.3%41.3%41.3%41.3%41.3%41.4%41.4%41.4%41.4%41.4%41.5%41.5%41.5%41.5%41.5%41.6%41.6%41.6%41.6%41.6%41.6%41.7%41.7%41.7%41.7%41.7%41.8%41.8%41.8%41.8%41.8%41.9%41.9%41.9%41.9%41.9%42.0%42.0%42.0%42.0%42.0%42.1%42.1%42.1%42.1%42.1%42.1%42.2%42.2%42.2%42.2%42.2%42.3%42.3%42.3%42.3%42.3%42.4%42.4%42.4%42.4%42.4%42.5%42.5%42.5%42.5%42.5%42.6%42.6%42.6%42.6%42.6%42.6%42.7%42.7%42.7%42.7%42.7%42.8%42.8%42.8%42.8%42.8%42.9%42.9%42.9%42.9%42.9%43.0%43.0%43.0%43.0%43.0%43.1%43.1%43.1%43.1%43.1%43.1%43.2%43.2%43.2%43.2%43.2%43.3%43.3%43.3%43.3%43.3%43.4%43.4%43.4%43.4%43.4%43.5%43.5%43.5%43.5%43.5%43.6%43.6%43.6%43.6%43.6%43.6%43.7%43.7%43.7%43.7%43.7%43.8%43.8%43.8%43.8%43.8%43.9%43.9%43.9%43.9%43.9%44.0%44.0%44.0%44.0%44.0%44.0%44.1%44.1%44.1%44.1%44.1%44.2%44.2%44.2%44.2%44.2%44.3%44.3%44.3%44.3%44.3%44.4%44.4%44.4%44.4%44.4%44.5%44.5%44.5%44.5%44.5%44.5%44.6%44.6%44.6%44.6%44.6%44.7%44.7%44.7%44.7%44.7%44.8%44.8%44.8%44.8%44.8%44.9%44.9%44.9%44.9%44.9%45.0%45.0%45.0%45.0%45.0%45.0%45.1%45.1%45.1%45.1%45.1%45.2%45.2%45.2%45.2%45.2%45.3%45.3%45.3%45.3%45.3%45.4%45.4%45.4%45.4%45.4%45.5%45.5%45.5%45.5%45.5%45.5%45.6%45.6%45.6%45.6%45.6%45.7%45.7%45.7%45.7%45.7%45.8%45.8%45.8%45.8%45.8%45.9%45.9%45.9%45.9%45.9%46.0%46.0%46.0%46.0%46.0%46.0%46.1%46.1%46.1%46.1%46.1%46.2%46.2%46.2%46.2%46.2%46.3%46.3%46.3%46.3%46.3%46.4%46.4%46.4%46.4%46.4%46.5%46.5%46.5%46.5%46.5%46.5%46.6%46.6%46.6%46.6%46.6%46.7%46.7%46.7%46.7%46.7%46.8%46.8%46.8%46.8%46.8%46.9%46.9%46.9%46.9%46.9%47.0%47.0%47.0%47.0%47.0%47.0%47.1%47.1%47.1%47.1%47.1%47.2%47.2%47.2%47.2%47.2%47.3%47.3%47.3%47.3%47.3%47.4%47.4%47.4%47.4%47.4%47.5%47.5%47.5%47.5%47.5%47.5%47.6%47.6%47.6%47.6%47.6%47.7%47.7%47.7%47.7%47.7%47.8%47.8%47.8%47.8%47.8%47.9%47.9%47.9%47.9%47.9%48.0%48.0%48.0%48.0%48.0%48.0%48.1%48.1%48.1%48.1%48.1%48.2%48.2%48.2%48.2%48.2%48.3%48.3%48.3%48.3%48.3%48.4%48.4%48.4%48.4%48.4%48.5%48.5%48.5%48.5%48.5%48.5%48.6%48.6%48.6%48.6%48.6%48.7%48.7%48.7%48.7%48.7%48.8%48.8%48.8%48.8%48.8%48.9%48.9%48.9%48.9%48.9%49.0%49.0%49.0%49.0%49.0%49.0%49.1%49.1%49.1%49.1%49.1%49.2%49.2%49.2%49.2%49.2%49.3%49.3%49.3%49.3%49.3%49.4%49.4%49.4%49.4%49.4%49.5%49.5%49.5%49.5%49.5%49.5%49.6%49.6%49.6%49.6%49.6%49.7%49.7%49.7%49.7%49.7%49.8%49.8%49.8%49.8%49.8%49.9%49.9%49.9%49.9%49.9%50.0%50.0%50.0%50.0%50.0%50.0%50.1%50.1%50.1%50.1%50.1%50.2%50.2%50.2%50.2%50.2%50.3%50.3%50.3%50.3%50.3%50.4%50.4%50.4%50.4%50.4%50.4%50.5%50.5%50.5%50.5%50.5%50.6%50.6%50.6%50.6%50.6%50.7%50.7%50.7%50.7%50.7%50.8%50.8%50.8%50.8%50.8%50.9%50.9%50.9%50.9%50.9%50.9%51.0%51.0%51.0%51.0%51.0%51.1%51.1%51.1%51.1%51.1%51.2%51.2%51.2%51.2%51.2%51.3%51.3%51.3%51.3%51.3%51.4%51.4%51.4%51.4%51.4%51.4%51.5%51.5%51.5%51.5%51.5%51.6%51.6%51.6%51.6%51.6%51.7%51.7%51.7%51.7%51.7%51.8%51.8%51.8%51.8%51.8%51.9%51.9%51.9%51.9%51.9%51.9%52.0%52.0%52.0%52.0%52.0%52.1%52.1%52.1%52.1%52.1%52.2%52.2%52.2%52.2%52.2%52.3%52.3%52.3%52.3%52.3%52.4%52.4%52.4%52.4%52.4%52.4%52.5%52.5%52.5%52.5%52.5%52.6%52.6%52.6%52.6%52.6%52.7%52.7%52.7%52.7%52.7%52.8%52.8%52.8%52.8%52.8%52.9%52.9%52.9%52.9%52.9%52.9%53.0%53.0%53.0%53.0%53.0%53.1%53.1%53.1%53.1%53.1%53.2%53.2%53.2%53.2%53.2%53.3%53.3%53.3%53.3%53.3%53.4%53.4%53.4%53.4%53.4%53.4%53.5%53.5%53.5%53.5%53.5%53.6%53.6%53.6%53.6%53.6%53.7%53.7%53.7%53.7%53.7%53.8%53.8%53.8%53.8%53.8%53.9%53.9%53.9%53.9%53.9%53.9%54.0%54.0%54.0%54.0%54.0%54.1%54.1%54.1%54.1%54.1%54.2%54.2%54.2%54.2%54.2%54.3%54.3%54.3%54.3%54.3%54.4%54.4%54.4%54.4%54.4%54.4%54.5%54.5%54.5%54.5%54.5%54.6%54.6%54.6%54.6%54.6%54.7%54.7%54.7%54.7%54.7%54.8%54.8%54.8%54.8%54.8%54.9%54.9%54.9%54.9%54.9%54.9%55.0%55.0%55.0%55.0%55.0%55.1%55.1%55.1%55.1%55.1%55.2%55.2%55.2%55.2%55.2%55.3%55.3%55.3%55.3%55.3%55.4%55.4%55.4%55.4%55.4%55.4%55.5%55.5%55.5%55.5%55.5%55.6%55.6%55.6%55.6%55.6%55.7%55.7%55.7%55.7%55.7%55.8%55.8%55.8%55.8%55.8%55.9%55.9%55.9%55.9%55.9%55.9%56.0%56.0%56.0%56.0%56.0%56.1%56.1%56.1%56.1%56.1%56.2%56.2%56.2%56.2%56.2%56.3%56.3%56.3%56.3%56.3%56.4%56.4%56.4%56.4%56.4%56.4%56.5%56.5%56.5%56.5%56.5%56.6%56.6%56.6%56.6%56.6%56.7%56.7%56.7%56.7%56.7%56.8%56.8%56.8%56.8%56.8%56.8%56.9%56.9%56.9%56.9%56.9%57.0%57.0%57.0%57.0%57.0%57.1%57.1%57.1%57.1%57.1%57.2%57.2%57.2%57.2%57.2%57.3%57.3%57.3%57.3%57.3%57.3%57.4%57.4%57.4%57.4%57.4%57.5%57.5%57.5%57.5%57.5%57.6%57.6%57.6%57.6%57.6%57.7%57.7%57.7%57.7%57.7%57.8%57.8%57.8%57.8%57.8%57.8%57.9%57.9%57.9%57.9%57.9%58.0%58.0%58.0%58.0%58.0%58.1%58.1%58.1%58.1%58.1%58.2%58.2%58.2%58.2%58.2%58.3%58.3%58.3%58.3%58.3%58.3%58.4%58.4%58.4%58.4%58.4%58.5%58.5%58.5%58.5%58.5%58.6%58.6%58.6%58.6%58.6%58.7%58.7%58.7%58.7%58.7%58.8%58.8%58.8%58.8%58.8%58.8%58.9%58.9%58.9%58.9%58.9%59.0%59.0%59.0%59.0%59.0%59.1%59.1%59.1%59.1%59.1%59.2%59.2%59.2%59.2%59.2%59.3%59.3%59.3%59.3%59.3%59.3%59.4%59.4%59.4%59.4%59.4%59.5%59.5%59.5%59.5%59.5%59.6%59.6%59.6%59.6%59.6%59.7%59.7%59.7%59.7%59.7%59.8%59.8%59.8%59.8%59.8%59.8%59.9%59.9%59.9%59.9%59.9%60.0%60.0%60.0%60.0%60.0%60.1%60.1%60.1%60.1%60.1%60.2%60.2%60.2%60.2%60.2%60.3%60.3%60.3%60.3%60.3%60.3%60.4%60.4%60.4%60.4%60.4%60.5%60.5%60.5%60.5%60.5%60.6%60.6%60.6%60.6%60.6%60.7%60.7%60.7%60.7%60.7%60.8%60.8%60.8%60.8%60.8%60.8%60.9%60.9%60.9%60.9%60.9%61.0%61.0%61.0%61.0%61.0%61.1%61.1%61.1%61.1%61.1%61.2%61.2%61.2%61.2%61.2%61.3%61.3%61.3%61.3%61.3%61.3%61.4%61.4%61.4%61.4%61.4%61.5%61.5%61.5%61.5%61.5%61.6%61.6%61.6%61.6%61.6%61.7%61.7%61.7%61.7%61.7%61.8%61.8%61.8%61.8%61.8%61.8%61.9%61.9%61.9%61.9%61.9%62.0%62.0%62.0%62.0%62.0%62.1%62.1%62.1%62.1%62.1%62.2%62.2%62.2%62.2%62.2%62.3%62.3%62.3%62.3%62.3%62.3%62.4%62.4%62.4%62.4%62.4%62.5%62.5%62.5%62.5%62.5%62.6%62.6%62.6%62.6%62.6%62.7%62.7%62.7%62.7%62.7%62.7%62.8%62.8%62.8%62.8%62.8%62.9%62.9%62.9%62.9%62.9%63.0%63.0%63.0%63.0%63.0%63.1%63.1%63.1%63.1%63.1%63.2%63.2%63.2%63.2%63.2%63.2%63.3%63.3%63.3%63.3%63.3%63.4%63.4%63.4%63.4%63.4%63.5%63.5%63.5%63.5%63.5%63.6%63.6%63.6%63.6%63.6%63.7%63.7%63.7%63.7%63.7%63.7%63.8%63.8%63.8%63.8%63.8%63.9%63.9%63.9%63.9%63.9%64.0%64.0%64.0%64.0%64.0%64.1%64.1%64.1%64.1%64.1%64.2%64.2%64.2%64.2%64.2%64.2%64.3%64.3%64.3%64.3%64.3%64.4%64.4%64.4%64.4%64.4%64.5%64.5%64.5%64.5%64.5%64.6%64.6%64.6%64.6%64.6%64.7%64.7%64.7%64.7%64.7%64.7%64.8%64.8%64.8%64.8%64.8%64.9%64.9%64.9%64.9%64.9%65.0%65.0%65.0%65.0%65.0%65.1%65.1%65.1%65.1%65.1%65.2%65.2%65.2%65.2%65.2%65.2%65.3%65.3%65.3%65.3%65.3%65.4%65.4%65.4%65.4%65.4%65.5%65.5%65.5%65.5%65.5%65.6%65.6%65.6%65.6%65.6%65.7%65.7%65.7%65.7%65.7%65.7%65.8%65.8%65.8%65.8%65.8%65.9%65.9%65.9%65.9%65.9%66.0%66.0%66.0%66.0%66.0%66.1%66.1%66.1%66.1%66.1%66.2%66.2%66.2%66.2%66.2%66.2%66.3%66.3%66.3%66.3%66.3%66.4%66.4%66.4%66.4%66.4%66.5%66.5%66.5%66.5%66.5%66.6%66.6%66.6%66.6%66.6%66.7%66.7%66.7%66.7%66.7%66.7%66.8%66.8%66.8%66.8%66.8%66.9%66.9%66.9%66.9%66.9%67.0%67.0%67.0%67.0%67.0%67.1%67.1%67.1%67.1%67.1%67.2%67.2%67.2%67.2%67.2%67.2%67.3%67.3%67.3%67.3%67.3%67.4%67.4%67.4%67.4%67.4%67.5%67.5%67.5%67.5%67.5%67.6%67.6%67.6%67.6%67.6%67.7%67.7%67.7%67.7%67.7%67.7%67.8%67.8%67.8%67.8%67.8%67.9%67.9%67.9%67.9%67.9%68.0%68.0%68.0%68.0%68.0%68.1%68.1%68.1%68.1%68.1%68.2%68.2%68.2%68.2%68.2%68.2%68.3%68.3%68.3%68.3%68.3%68.4%68.4%68.4%68.4%68.4%68.5%68.5%68.5%68.5%68.5%68.6%68.6%68.6%68.6%68.6%68.7%68.7%68.7%68.7%68.7%68.7%68.8%68.8%68.8%68.8%68.8%68.9%68.9%68.9%68.9%68.9%69.0%69.0%69.0%69.0%69.0%69.1%69.1%69.1%69.1%69.1%69.1%69.2%69.2%69.2%69.2%69.2%69.3%69.3%69.3%69.3%69.3%69.4%69.4%69.4%69.4%69.4%69.5%69.5%69.5%69.5%69.5%69.6%69.6%69.6%69.6%69.6%69.6%69.7%69.7%69.7%69.7%69.7%69.8%69.8%69.8%69.8%69.8%69.9%69.9%69.9%69.9%69.9%70.0%70.0%70.0%70.0%70.0%70.1%70.1%70.1%70.1%70.1%70.1%70.2%70.2%70.2%70.2%70.2%70.3%70.3%70.3%70.3%70.3%70.4%70.4%70.4%70.4%70.4%70.5%70.5%70.5%70.5%70.5%70.6%70.6%70.6%70.6%70.6%70.6%70.7%70.7%70.7%70.7%70.7%70.8%70.8%70.8%70.8%70.8%70.9%70.9%70.9%70.9%70.9%71.0%71.0%71.0%71.0%71.0%71.1%71.1%71.1%71.1%71.1%71.1%71.2%71.2%71.2%71.2%71.2%71.3%71.3%71.3%71.3%71.3%71.4%71.4%71.4%71.4%71.4%71.5%71.5%71.5%71.5%71.5%71.6%71.6%71.6%71.6%71.6%71.6%71.7%71.7%71.7%71.7%71.7%71.8%71.8%71.8%71.8%71.8%71.9%71.9%71.9%71.9%71.9%72.0%72.0%72.0%72.0%72.0%72.1%72.1%72.1%72.1%72.1%72.1%72.2%72.2%72.2%72.2%72.2%72.3%72.3%72.3%72.3%72.3%72.4%72.4%72.4%72.4%72.4%72.5%72.5%72.5%72.5%72.5%72.6%72.6%72.6%72.6%72.6%72.6%72.7%72.7%72.7%72.7%72.7%72.8%72.8%72.8%72.8%72.8%72.9%72.9%72.9%72.9%72.9%73.0%73.0%73.0%73.0%73.0%73.1%73.1%73.1%73.1%73.1%73.1%73.2%73.2%73.2%73.2%73.2%73.3%73.3%73.3%73.3%73.3%73.4%73.4%73.4%73.4%73.4%73.5%73.5%73.5%73.5%73.5%73.6%73.6%73.6%73.6%73.6%73.6%73.7%73.7%73.7%73.7%73.7%73.8%73.8%73.8%73.8%73.8%73.9%73.9%73.9%73.9%73.9%74.0%74.0%74.0%74.0%74.0%74.1%74.1%74.1%74.1%74.1%74.1%74.2%74.2%74.2%74.2%74.2%74.3%74.3%74.3%74.3%74.3%74.4%74.4%74.4%74.4%74.4%74.5%74.5%74.5%74.5%74.5%74.6%74.6%74.6%74.6%74.6%74.6%74.7%74.7%74.7%74.7%74.7%74.8%74.8%74.8%74.8%74.8%74.9%74.9%74.9%74.9%74.9%75.0%75.0%75.0%75.0%75.0%75.1%75.1%75.1%75.1%75.1%75.1%75.2%75.2%75.2%75.2%75.2%75.3%75.3%75.3%75.3%75.3%75.4%75.4%75.4%75.4%75.4%75.5%75.5%75.5%75.5%75.5%75.5%75.6%75.6%75.6%75.6%75.6%75.7%75.7%75.7%75.7%75.7%75.8%75.8%75.8%75.8%75.8%75.9%75.9%75.9%75.9%75.9%76.0%76.0%76.0%76.0%76.0%76.0%76.1%76.1%76.1%76.1%76.1%76.2%76.2%76.2%76.2%76.2%76.3%76.3%76.3%76.3%76.3%76.4%76.4%76.4%76.4%76.4%76.5%76.5%76.5%76.5%76.5%76.5%76.6%76.6%76.6%76.6%76.6%76.7%76.7%76.7%76.7%76.7%76.8%76.8%76.8%76.8%76.8%76.9%76.9%76.9%76.9%76.9%77.0%77.0%77.0%77.0%77.0%77.0%77.1%77.1%77.1%77.1%77.1%77.2%77.2%77.2%77.2%77.2%77.3%77.3%77.3%77.3%77.3%77.4%77.4%77.4%77.4%77.4%77.5%77.5%77.5%77.5%77.5%77.5%77.6%77.6%77.6%77.6%77.6%77.7%77.7%77.7%77.7%77.7%77.8%77.8%77.8%77.8%77.8%77.9%77.9%77.9%77.9%77.9%78.0%78.0%78.0%78.0%78.0%78.0%78.1%78.1%78.1%78.1%78.1%78.2%78.2%78.2%78.2%78.2%78.3%78.3%78.3%78.3%78.3%78.4%78.4%78.4%78.4%78.4%78.5%78.5%78.5%78.5%78.5%78.5%78.6%78.6%78.6%78.6%78.6%78.7%78.7%78.7%78.7%78.7%78.8%78.8%78.8%78.8%78.8%78.9%78.9%78.9%78.9%78.9%79.0%79.0%79.0%79.0%79.0%79.0%79.1%79.1%79.1%79.1%79.1%79.2%79.2%79.2%79.2%79.2%79.3%79.3%79.3%79.3%79.3%79.4%79.4%79.4%79.4%79.4%79.5%79.5%79.5%79.5%79.5%79.5%79.6%79.6%79.6%79.6%79.6%79.7%79.7%79.7%79.7%79.7%79.8%79.8%79.8%79.8%79.8%79.9%79.9%79.9%79.9%79.9%80.0%80.0%80.0%80.0%80.0%80.0%80.1%80.1%80.1%80.1%80.1%80.2%80.2%80.2%80.2%80.2%80.3%80.3%80.3%80.3%80.3%80.4%80.4%80.4%80.4%80.4%80.5%80.5%80.5%80.5%80.5%80.5%80.6%80.6%80.6%80.6%80.6%80.7%80.7%80.7%80.7%80.7%80.8%80.8%80.8%80.8%80.8%80.9%80.9%80.9%80.9%80.9%81.0%81.0%81.0%81.0%81.0%81.0%81.1%81.1%81.1%81.1%81.1%81.2%81.2%81.2%81.2%81.2%81.3%81.3%81.3%81.3%81.3%81.4%81.4%81.4%81.4%81.4%81.5%81.5%81.5%81.5%81.5%81.5%81.6%81.6%81.6%81.6%81.6%81.7%81.7%81.7%81.7%81.7%81.8%81.8%81.8%81.8%81.8%81.9%81.9%81.9%81.9%81.9%81.9%82.0%82.0%82.0%82.0%82.0%82.1%82.1%82.1%82.1%82.1%82.2%82.2%82.2%82.2%82.2%82.3%82.3%82.3%82.3%82.3%82.4%82.4%82.4%82.4%82.4%82.4%82.5%82.5%82.5%82.5%82.5%82.6%82.6%82.6%82.6%82.6%82.7%82.7%82.7%82.7%82.7%82.8%82.8%82.8%82.8%82.8%82.9%82.9%82.9%82.9%82.9%82.9%83.0%83.0%83.0%83.0%83.0%83.1%83.1%83.1%83.1%83.1%83.2%83.2%83.2%83.2%83.2%83.3%83.3%83.3%83.3%83.3%83.4%83.4%83.4%83.4%83.4%83.4%83.5%83.5%83.5%83.5%83.5%83.6%83.6%83.6%83.6%83.6%83.7%83.7%83.7%83.7%83.7%83.8%83.8%83.8%83.8%83.8%83.9%83.9%83.9%83.9%83.9%83.9%84.0%84.0%84.0%84.0%84.0%84.1%84.1%84.1%84.1%84.1%84.2%84.2%84.2%84.2%84.2%84.3%84.3%84.3%84.3%84.3%84.4%84.4%84.4%84.4%84.4%84.4%84.5%84.5%84.5%84.5%84.5%84.6%84.6%84.6%84.6%84.6%84.7%84.7%84.7%84.7%84.7%84.8%84.8%84.8%84.8%84.8%84.9%84.9%84.9%84.9%84.9%84.9%85.0%85.0%85.0%85.0%85.0%85.1%85.1%85.1%85.1%85.1%85.2%85.2%85.2%85.2%85.2%85.3%85.3%85.3%85.3%85.3%85.4%85.4%85.4%85.4%85.4%85.4%85.5%85.5%85.5%85.5%85.5%85.6%85.6%85.6%85.6%85.6%85.7%85.7%85.7%85.7%85.7%85.8%85.8%85.8%85.8%85.8%85.9%85.9%85.9%85.9%85.9%85.9%86.0%86.0%86.0%86.0%86.0%86.1%86.1%86.1%86.1%86.1%86.2%86.2%86.2%86.2%86.2%86.3%86.3%86.3%86.3%86.3%86.4%86.4%86.4%86.4%86.4%86.4%86.5%86.5%86.5%86.5%86.5%86.6%86.6%86.6%86.6%86.6%86.7%86.7%86.7%86.7%86.7%86.8%86.8%86.8%86.8%86.8%86.9%86.9%86.9%86.9%86.9%86.9%87.0%87.0%87.0%87.0%87.0%87.1%87.1%87.1%87.1%87.1%87.2%87.2%87.2%87.2%87.2%87.3%87.3%87.3%87.3%87.3%87.4%87.4%87.4%87.4%87.4%87.4%87.5%87.5%87.5%87.5%87.5%87.6%87.6%87.6%87.6%87.6%87.7%87.7%87.7%87.7%87.7%87.8%87.8%87.8%87.8%87.8%87.8%87.9%87.9%87.9%87.9%87.9%88.0%88.0%88.0%88.0%88.0%88.1%88.1%88.1%88.1%88.1%88.2%88.2%88.2%88.2%88.2%88.3%88.3%88.3%88.3%88.3%88.3%88.4%88.4%88.4%88.4%88.4%88.5%88.5%88.5%88.5%88.5%88.6%88.6%88.6%88.6%88.6%88.7%88.7%88.7%88.7%88.7%88.8%88.8%88.8%88.8%88.8%88.8%88.9%88.9%88.9%88.9%88.9%89.0%89.0%89.0%89.0%89.0%89.1%89.1%89.1%89.1%89.1%89.2%89.2%89.2%89.2%89.2%89.3%89.3%89.3%89.3%89.3%89.3%89.4%89.4%89.4%89.4%89.4%89.5%89.5%89.5%89.5%89.5%89.6%89.6%89.6%89.6%89.6%89.7%89.7%89.7%89.7%89.7%89.8%89.8%89.8%89.8%89.8%89.8%89.9%89.9%89.9%89.9%89.9%90.0%90.0%90.0%90.0%90.0%90.1%90.1%90.1%90.1%90.1%90.2%90.2%90.2%90.2%90.2%90.3%90.3%90.3%90.3%90.3%90.3%90.4%90.4%90.4%90.4%90.4%90.5%90.5%90.5%90.5%90.5%90.6%90.6%90.6%90.6%90.6%90.7%90.7%90.7%90.7%90.7%90.8%90.8%90.8%90.8%90.8%90.8%90.9%90.9%90.9%90.9%90.9%91.0%91.0%91.0%91.0%91.0%91.1%91.1%91.1%91.1%91.1%91.2%91.2%91.2%91.2%91.2%91.3%91.3%91.3%91.3%91.3%91.3%91.4%91.4%91.4%91.4%91.4%91.5%91.5%91.5%91.5%91.5%91.6%91.6%91.6%91.6%91.6%91.7%91.7%91.7%91.7%91.7%91.8%91.8%91.8%91.8%91.8%91.8%91.9%91.9%91.9%91.9%91.9%92.0%92.0%92.0%92.0%92.0%92.1%92.1%92.1%92.1%92.1%92.2%92.2%92.2%92.2%92.2%92.3%92.3%92.3%92.3%92.3%92.3%92.4%92.4%92.4%92.4%92.4%92.5%92.5%92.5%92.5%92.5%92.6%92.6%92.6%92.6%92.6%92.7%92.7%92.7%92.7%92.7%92.8%92.8%92.8%92.8%92.8%92.8%92.9%92.9%92.9%92.9%92.9%93.0%93.0%93.0%93.0%93.0%93.1%93.1%93.1%93.1%93.1%93.2%93.2%93.2%93.2%93.2%93.3%93.3%93.3%93.3%93.3%93.3%93.4%93.4%93.4%93.4%93.4%93.5%93.5%93.5%93.5%93.5%93.6%93.6%93.6%93.6%93.6%93.7%93.7%93.7%93.7%93.7%93.8%93.8%93.8%93.8%93.8%93.8%93.9%93.9%93.9%93.9%93.9%94.0%94.0%94.0%94.0%94.0%94.1%94.1%94.1%94.1%94.1%94.2%94.2%94.2%94.2%94.2%94.2%94.3%94.3%94.3%94.3%94.3%94.4%94.4%94.4%94.4%94.4%94.5%94.5%94.5%94.5%94.5%94.6%94.6%94.6%94.6%94.6%94.7%94.7%94.7%94.7%94.7%94.7%94.8%94.8%94.8%94.8%94.8%94.9%94.9%94.9%94.9%94.9%95.0%95.0%95.0%95.0%95.0%95.1%95.1%95.1%95.1%95.1%95.2%95.2%95.2%95.2%95.2%95.2%95.3%95.3%95.3%95.3%95.3%95.4%95.4%95.4%95.4%95.4%95.5%95.5%95.5%95.5%95.5%95.6%95.6%95.6%95.6%95.6%95.7%95.7%95.7%95.7%95.7%95.7%95.8%95.8%95.8%95.8%95.8%95.9%95.9%95.9%95.9%95.9%96.0%96.0%96.0%96.0%96.0%96.1%96.1%96.1%96.1%96.1%96.2%96.2%96.2%96.2%96.2%96.2%96.3%96.3%96.3%96.3%96.3%96.4%96.4%96.4%96.4%96.4%96.5%96.5%96.5%96.5%96.5%96.6%96.6%96.6%96.6%96.6%96.7%96.7%96.7%96.7%96.7%96.7%96.8%96.8%96.8%96.8%96.8%96.9%96.9%96.9%96.9%96.9%97.0%97.0%97.0%97.0%97.0%97.1%97.1%97.1%97.1%97.1%97.2%97.2%97.2%97.2%97.2%97.2%97.3%97.3%97.3%97.3%97.3%97.4%97.4%97.4%97.4%97.4%97.5%97.5%97.5%97.5%97.5%97.6%97.6%97.6%97.6%97.6%97.7%97.7%97.7%97.7%97.7%97.7%97.8%97.8%97.8%97.8%97.8%97.9%97.9%97.9%97.9%97.9%98.0%98.0%98.0%98.0%98.0%98.1%98.1%98.1%98.1%98.1%98.2%98.2%98.2%98.2%98.2%98.2%98.3%98.3%98.3%98.3%98.3%98.4%98.4%98.4%98.4%98.4%98.5%98.5%98.5%98.5%98.5%98.6%98.6%98.6%98.6%98.6%98.7%98.7%98.7%98.7%98.7%98.7%98.8%98.8%98.8%98.8%98.8%98.9%98.9%98.9%98.9%98.9%99.0%99.0%99.0%99.0%99.0%99.1%99.1%99.1%99.1%99.1%99.2%99.2%99.2%99.2%99.2%99.2%99.3%99.3%99.3%99.3%99.3%99.4%99.4%99.4%99.4%99.4%99.5%99.5%99.5%99.5%99.5%99.6%99.6%99.6%99.6%99.6%99.7%99.7%99.7%99.7%99.7%99.7%99.8%99.8%99.8%99.8%99.8%99.9%99.9%99.9%99.9%99.9%100.0%100.0%100.0%100.0%
cuda
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz
Extracting ../data/cifar-10-python.tar.gz to ../data

Training with L2 Regularization: 0.001
Current time: 1732614347.7152; Train Epoch: 1 [0/50000 (0%)]	Loss: 2.303788
Current time: 1732614352.6221; Train Epoch: 1 [25600/50000 (51%)]	Loss: 2.302922
Current time: 1732614359.0421; Test Epoch: 1, Test set: Average loss: 2.3027, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614359.0687; Train Epoch: 2 [0/50000 (0%)]	Loss: 2.303251
Current time: 1732614364.0099; Train Epoch: 2 [25600/50000 (51%)]	Loss: 2.304575
Current time: 1732614370.4618; Test Epoch: 2, Test set: Average loss: 2.3026, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614370.4883; Train Epoch: 3 [0/50000 (0%)]	Loss: 2.302280
Current time: 1732614375.4344; Train Epoch: 3 [25600/50000 (51%)]	Loss: 2.302074
Current time: 1732614381.8525; Test Epoch: 3, Test set: Average loss: 2.3027, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614381.8789; Train Epoch: 4 [0/50000 (0%)]	Loss: 2.302218
Current time: 1732614386.8304; Train Epoch: 4 [25600/50000 (51%)]	Loss: 2.302660
Current time: 1732614393.2562; Test Epoch: 4, Test set: Average loss: 2.3027, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614393.2827; Train Epoch: 5 [0/50000 (0%)]	Loss: 2.304956
Current time: 1732614398.2227; Train Epoch: 5 [25600/50000 (51%)]	Loss: 2.302290
Current time: 1732614404.6345; Test Epoch: 5, Test set: Average loss: 2.3038, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614404.6610; Train Epoch: 6 [0/50000 (0%)]	Loss: 2.299404
Current time: 1732614409.6109; Train Epoch: 6 [25600/50000 (51%)]	Loss: 2.304076
Current time: 1732614416.0401; Test Epoch: 6, Test set: Average loss: 2.3028, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614416.0666; Train Epoch: 7 [0/50000 (0%)]	Loss: 2.304478
Current time: 1732614421.0090; Train Epoch: 7 [25600/50000 (51%)]	Loss: 2.303746
Current time: 1732614427.4317; Test Epoch: 7, Test set: Average loss: 2.3029, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614427.4585; Train Epoch: 8 [0/50000 (0%)]	Loss: 2.304958
Current time: 1732614432.4080; Train Epoch: 8 [25600/50000 (51%)]	Loss: 2.301675
Current time: 1732614438.8344; Test Epoch: 8, Test set: Average loss: 2.3034, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614438.8610; Train Epoch: 9 [0/50000 (0%)]	Loss: 2.303315
Current time: 1732614443.8011; Train Epoch: 9 [25600/50000 (51%)]	Loss: 2.301136
Current time: 1732614450.2267; Test Epoch: 9, Test set: Average loss: 2.3035, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614450.2532; Train Epoch: 10 [0/50000 (0%)]	Loss: 2.303280
Current time: 1732614455.1892; Train Epoch: 10 [25600/50000 (51%)]	Loss: 2.307299
Current time: 1732614461.6117; Test Epoch: 10, Test set: Average loss: 2.3027, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614461.6384; Train Epoch: 11 [0/50000 (0%)]	Loss: 2.305367
Current time: 1732614466.5717; Train Epoch: 11 [25600/50000 (51%)]	Loss: 2.305753
Current time: 1732614472.9886; Test Epoch: 11, Test set: Average loss: 2.3028, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614473.0151; Train Epoch: 12 [0/50000 (0%)]	Loss: 2.303375
Current time: 1732614477.9500; Train Epoch: 12 [25600/50000 (51%)]	Loss: 2.303450
Current time: 1732614484.3630; Test Epoch: 12, Test set: Average loss: 2.3029, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614484.3897; Train Epoch: 13 [0/50000 (0%)]	Loss: 2.300734
Current time: 1732614489.3354; Train Epoch: 13 [25600/50000 (51%)]	Loss: 2.302754
Current time: 1732614495.7542; Test Epoch: 13, Test set: Average loss: 2.3027, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614495.7808; Train Epoch: 14 [0/50000 (0%)]	Loss: 2.301159
Current time: 1732614500.7171; Train Epoch: 14 [25600/50000 (51%)]	Loss: 2.300761
Current time: 1732614507.1287; Test Epoch: 14, Test set: Average loss: 2.3037, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614507.1554; Train Epoch: 15 [0/50000 (0%)]	Loss: 2.301447
Current time: 1732614512.0879; Train Epoch: 15 [25600/50000 (51%)]	Loss: 2.303235
Current time: 1732614518.4978; Test Epoch: 15, Test set: Average loss: 2.3029, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614518.5243; Train Epoch: 16 [0/50000 (0%)]	Loss: 2.302495
Current time: 1732614523.4538; Train Epoch: 16 [25600/50000 (51%)]	Loss: 2.304792
Current time: 1732614529.8587; Test Epoch: 16, Test set: Average loss: 2.3037, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614529.8856; Train Epoch: 17 [0/50000 (0%)]	Loss: 2.309343
Current time: 1732614534.8249; Train Epoch: 17 [25600/50000 (51%)]	Loss: 2.305477
Current time: 1732614541.2444; Test Epoch: 17, Test set: Average loss: 2.3026, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614541.2708; Train Epoch: 18 [0/50000 (0%)]	Loss: 2.301932
Current time: 1732614546.2095; Train Epoch: 18 [25600/50000 (51%)]	Loss: 2.313345
Current time: 1732614552.6256; Test Epoch: 18, Test set: Average loss: 2.3029, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614552.6520; Train Epoch: 19 [0/50000 (0%)]	Loss: 2.305236
Current time: 1732614557.5875; Train Epoch: 19 [25600/50000 (51%)]	Loss: 2.303434
Current time: 1732614564.0459; Test Epoch: 19, Test set: Average loss: 2.3027, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614564.0724; Train Epoch: 20 [0/50000 (0%)]	Loss: 2.301184
Current time: 1732614569.0137; Train Epoch: 20 [25600/50000 (51%)]	Loss: 2.303829
Current time: 1732614575.4326; Test Epoch: 20, Test set: Average loss: 2.3028, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614575.4592; Train Epoch: 21 [0/50000 (0%)]	Loss: 2.301594
Current time: 1732614580.4035; Train Epoch: 21 [25600/50000 (51%)]	Loss: 2.301308
Current time: 1732614586.8277; Test Epoch: 21, Test set: Average loss: 2.3029, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614586.8545; Train Epoch: 22 [0/50000 (0%)]	Loss: 2.303415
Current time: 1732614591.7857; Train Epoch: 22 [25600/50000 (51%)]	Loss: 2.299181
Current time: 1732614598.1989; Test Epoch: 22, Test set: Average loss: 2.3026, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614598.2254; Train Epoch: 23 [0/50000 (0%)]	Loss: 2.304338
Current time: 1732614603.1598; Train Epoch: 23 [25600/50000 (51%)]	Loss: 2.303308
Current time: 1732614609.5734; Test Epoch: 23, Test set: Average loss: 2.3027, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614609.5998; Train Epoch: 24 [0/50000 (0%)]	Loss: 2.302370
Current time: 1732614614.5319; Train Epoch: 24 [25600/50000 (51%)]	Loss: 2.300188
Current time: 1732614620.9391; Test Epoch: 24, Test set: Average loss: 2.3028, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614620.9655; Train Epoch: 25 [0/50000 (0%)]	Loss: 2.305569
Current time: 1732614625.9066; Train Epoch: 25 [25600/50000 (51%)]	Loss: 2.304031
Current time: 1732614632.3264; Test Epoch: 25, Test set: Average loss: 2.3028, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614632.3530; Train Epoch: 26 [0/50000 (0%)]	Loss: 2.302241
Current time: 1732614637.2942; Train Epoch: 26 [25600/50000 (51%)]	Loss: 2.302670
Current time: 1732614643.7159; Test Epoch: 26, Test set: Average loss: 2.3028, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614643.7424; Train Epoch: 27 [0/50000 (0%)]	Loss: 2.301262
Current time: 1732614648.6867; Train Epoch: 27 [25600/50000 (51%)]	Loss: 2.308444
Current time: 1732614655.1054; Test Epoch: 27, Test set: Average loss: 2.3028, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614655.1319; Train Epoch: 28 [0/50000 (0%)]	Loss: 2.304163
Current time: 1732614660.0624; Train Epoch: 28 [25600/50000 (51%)]	Loss: 2.307077
Current time: 1732614666.4740; Test Epoch: 28, Test set: Average loss: 2.3027, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614666.5006; Train Epoch: 29 [0/50000 (0%)]	Loss: 2.300822
Current time: 1732614671.4471; Train Epoch: 29 [25600/50000 (51%)]	Loss: 2.302538
Current time: 1732614677.8699; Test Epoch: 29, Test set: Average loss: 2.3028, Accuracy: 1000/10000 (10.0000%)

Current time: 1732614677.8964; Train Epoch: 30 [0/50000 (0%)]	Loss: 2.300404
Current time: 1732614682.8334; Train Epoch: 30 [25600/50000 (51%)]	Loss: 2.303765
Current time: 1732614689.2487; Test Epoch: 30, Test set: Average loss: 2.3029, Accuracy: 1000/10000 (10.0000%)


Training with L2 Regularization: 0.0001
Current time: 1732614689.5778; Train Epoch: 1 [0/50000 (0%)]	Loss: 2.304155
Current time: 1732614694.5204; Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.915747
Current time: 1732614700.9871; Test Epoch: 1, Test set: Average loss: 1.7412, Accuracy: 2927/10000 (29.2700%)

Current time: 1732614701.0138; Train Epoch: 2 [0/50000 (0%)]	Loss: 1.738289
Current time: 1732614705.9646; Train Epoch: 2 [25600/50000 (51%)]	Loss: 1.551132
Current time: 1732614712.3982; Test Epoch: 2, Test set: Average loss: 1.3833, Accuracy: 4686/10000 (46.8600%)

Current time: 1732614712.4248; Train Epoch: 3 [0/50000 (0%)]	Loss: 1.409220
Current time: 1732614717.3711; Train Epoch: 3 [25600/50000 (51%)]	Loss: 1.451568
Current time: 1732614723.7964; Test Epoch: 3, Test set: Average loss: 1.1989, Accuracy: 5667/10000 (56.6700%)

Current time: 1732614723.8230; Train Epoch: 4 [0/50000 (0%)]	Loss: 1.111530
Current time: 1732614728.7504; Train Epoch: 4 [25600/50000 (51%)]	Loss: 1.157019
Current time: 1732614735.1617; Test Epoch: 4, Test set: Average loss: 0.9882, Accuracy: 6561/10000 (65.6100%)

Current time: 1732614735.1883; Train Epoch: 5 [0/50000 (0%)]	Loss: 0.960938
Current time: 1732614740.1126; Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.903602
Current time: 1732614746.5183; Test Epoch: 5, Test set: Average loss: 0.9756, Accuracy: 6582/10000 (65.8200%)

Current time: 1732614746.5449; Train Epoch: 6 [0/50000 (0%)]	Loss: 0.828781
Current time: 1732614751.4711; Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.980617
Current time: 1732614757.8714; Test Epoch: 6, Test set: Average loss: 0.8286, Accuracy: 7187/10000 (71.8700%)

Current time: 1732614757.8979; Train Epoch: 7 [0/50000 (0%)]	Loss: 0.597141
Current time: 1732614762.8237; Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.735874
Current time: 1732614769.2230; Test Epoch: 7, Test set: Average loss: 0.8349, Accuracy: 7258/10000 (72.5800%)

Current time: 1732614769.2496; Train Epoch: 8 [0/50000 (0%)]	Loss: 0.641167
Current time: 1732614774.1687; Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.586812
Current time: 1732614780.5634; Test Epoch: 8, Test set: Average loss: 0.7855, Accuracy: 7408/10000 (74.0800%)

Current time: 1732614780.5900; Train Epoch: 9 [0/50000 (0%)]	Loss: 0.438338
Current time: 1732614785.5090; Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.675465
Current time: 1732614791.9075; Test Epoch: 9, Test set: Average loss: 0.7975, Accuracy: 7425/10000 (74.2500%)

Current time: 1732614791.9340; Train Epoch: 10 [0/50000 (0%)]	Loss: 0.493472
Current time: 1732614796.8537; Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.678875
Current time: 1732614803.2402; Test Epoch: 10, Test set: Average loss: 0.8357, Accuracy: 7290/10000 (72.9000%)

Current time: 1732614803.2668; Train Epoch: 11 [0/50000 (0%)]	Loss: 0.497298
Current time: 1732614808.1868; Train Epoch: 11 [25600/50000 (51%)]	Loss: 0.493944
Current time: 1732614814.5844; Test Epoch: 11, Test set: Average loss: 0.8514, Accuracy: 7395/10000 (73.9500%)

Current time: 1732614814.6115; Train Epoch: 12 [0/50000 (0%)]	Loss: 0.459007
Current time: 1732614819.5299; Train Epoch: 12 [25600/50000 (51%)]	Loss: 0.494622
Current time: 1732614825.9248; Test Epoch: 12, Test set: Average loss: 0.7847, Accuracy: 7540/10000 (75.4000%)

Current time: 1732614825.9514; Train Epoch: 13 [0/50000 (0%)]	Loss: 0.431482
Current time: 1732614830.8720; Train Epoch: 13 [25600/50000 (51%)]	Loss: 0.583501
Current time: 1732614837.2686; Test Epoch: 13, Test set: Average loss: 0.8019, Accuracy: 7514/10000 (75.1400%)

Current time: 1732614837.2951; Train Epoch: 14 [0/50000 (0%)]	Loss: 0.361016
Current time: 1732614842.2122; Train Epoch: 14 [25600/50000 (51%)]	Loss: 0.445068
Current time: 1732614848.6059; Test Epoch: 14, Test set: Average loss: 0.8468, Accuracy: 7530/10000 (75.3000%)

Current time: 1732614848.6325; Train Epoch: 15 [0/50000 (0%)]	Loss: 0.318332
Current time: 1732614853.5531; Train Epoch: 15 [25600/50000 (51%)]	Loss: 0.420663
Current time: 1732614859.9486; Test Epoch: 15, Test set: Average loss: 0.8734, Accuracy: 7509/10000 (75.0900%)

Current time: 1732614859.9751; Train Epoch: 16 [0/50000 (0%)]	Loss: 0.279560
Current time: 1732614864.8911; Train Epoch: 16 [25600/50000 (51%)]	Loss: 0.320370
Current time: 1732614871.2853; Test Epoch: 16, Test set: Average loss: 0.8621, Accuracy: 7516/10000 (75.1600%)

Current time: 1732614871.3119; Train Epoch: 17 [0/50000 (0%)]	Loss: 0.299540
Current time: 1732614876.2335; Train Epoch: 17 [25600/50000 (51%)]	Loss: 0.429477
Current time: 1732614882.6291; Test Epoch: 17, Test set: Average loss: 0.8449, Accuracy: 7595/10000 (75.9500%)

Current time: 1732614882.6556; Train Epoch: 18 [0/50000 (0%)]	Loss: 0.349756
Current time: 1732614887.5733; Train Epoch: 18 [25600/50000 (51%)]	Loss: 0.357817
Current time: 1732614894.0054; Test Epoch: 18, Test set: Average loss: 1.0057, Accuracy: 7495/10000 (74.9500%)

Current time: 1732614894.0319; Train Epoch: 19 [0/50000 (0%)]	Loss: 0.179189
Current time: 1732614898.9487; Train Epoch: 19 [25600/50000 (51%)]	Loss: 0.424694
Current time: 1732614905.3426; Test Epoch: 19, Test set: Average loss: 0.9378, Accuracy: 7533/10000 (75.3300%)

Current time: 1732614905.3692; Train Epoch: 20 [0/50000 (0%)]	Loss: 0.253076
Current time: 1732614910.2848; Train Epoch: 20 [25600/50000 (51%)]	Loss: 0.212150
Current time: 1732614916.6794; Test Epoch: 20, Test set: Average loss: 0.9801, Accuracy: 7557/10000 (75.5700%)

Current time: 1732614916.7059; Train Epoch: 21 [0/50000 (0%)]	Loss: 0.186842
Current time: 1732614921.6286; Train Epoch: 21 [25600/50000 (51%)]	Loss: 0.146671
Current time: 1732614928.0243; Test Epoch: 21, Test set: Average loss: 0.9735, Accuracy: 7545/10000 (75.4500%)

Current time: 1732614928.0510; Train Epoch: 22 [0/50000 (0%)]	Loss: 0.150957
Current time: 1732614932.9699; Train Epoch: 22 [25600/50000 (51%)]	Loss: 0.179612
Current time: 1732614939.3574; Test Epoch: 22, Test set: Average loss: 0.9428, Accuracy: 7566/10000 (75.6600%)

Current time: 1732614939.3840; Train Epoch: 23 [0/50000 (0%)]	Loss: 0.223512
Current time: 1732614944.3001; Train Epoch: 23 [25600/50000 (51%)]	Loss: 0.427160
Current time: 1732614950.6944; Test Epoch: 23, Test set: Average loss: 1.1370, Accuracy: 7509/10000 (75.0900%)

Current time: 1732614950.7209; Train Epoch: 24 [0/50000 (0%)]	Loss: 0.255104
Current time: 1732614955.6380; Train Epoch: 24 [25600/50000 (51%)]	Loss: 0.177049
Current time: 1732614962.0296; Test Epoch: 24, Test set: Average loss: 1.0817, Accuracy: 7474/10000 (74.7400%)

Current time: 1732614962.0561; Train Epoch: 25 [0/50000 (0%)]	Loss: 0.243820
Current time: 1732614966.9727; Train Epoch: 25 [25600/50000 (51%)]	Loss: 0.241596
Current time: 1732614973.3773; Test Epoch: 25, Test set: Average loss: 1.0344, Accuracy: 7533/10000 (75.3300%)

Current time: 1732614973.4040; Train Epoch: 26 [0/50000 (0%)]	Loss: 0.285090
Current time: 1732614978.3313; Train Epoch: 26 [25600/50000 (51%)]	Loss: 0.150346
Current time: 1732614984.7385; Test Epoch: 26, Test set: Average loss: 1.0688, Accuracy: 7515/10000 (75.1500%)

Current time: 1732614984.7650; Train Epoch: 27 [0/50000 (0%)]	Loss: 0.187716
Current time: 1732614989.6807; Train Epoch: 27 [25600/50000 (51%)]	Loss: 0.187570
Current time: 1732614996.0702; Test Epoch: 27, Test set: Average loss: 1.0773, Accuracy: 7550/10000 (75.5000%)

Current time: 1732614996.0968; Train Epoch: 28 [0/50000 (0%)]	Loss: 0.132819
Current time: 1732615001.0077; Train Epoch: 28 [25600/50000 (51%)]	Loss: 0.161773
Current time: 1732615007.3967; Test Epoch: 28, Test set: Average loss: 1.1940, Accuracy: 7498/10000 (74.9800%)

Current time: 1732615007.4232; Train Epoch: 29 [0/50000 (0%)]	Loss: 0.177949
Current time: 1732615012.3402; Train Epoch: 29 [25600/50000 (51%)]	Loss: 0.256996
Current time: 1732615018.7339; Test Epoch: 29, Test set: Average loss: 1.1335, Accuracy: 7543/10000 (75.4300%)

Current time: 1732615018.7604; Train Epoch: 30 [0/50000 (0%)]	Loss: 0.093423
Current time: 1732615023.6791; Train Epoch: 30 [25600/50000 (51%)]	Loss: 0.221687
Current time: 1732615030.0787; Test Epoch: 30, Test set: Average loss: 1.1395, Accuracy: 7488/10000 (74.8800%)


Training with L2 Regularization: 1e-06
Current time: 1732615030.3944; Train Epoch: 1 [0/50000 (0%)]	Loss: 2.304524
Current time: 1732615035.3105; Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.831316
Current time: 1732615041.7053; Test Epoch: 1, Test set: Average loss: 1.5663, Accuracy: 3961/10000 (39.6100%)

Current time: 1732615041.7317; Train Epoch: 2 [0/50000 (0%)]	Loss: 1.577632
Current time: 1732615046.6491; Train Epoch: 2 [25600/50000 (51%)]	Loss: 1.224008
Current time: 1732615053.0888; Test Epoch: 2, Test set: Average loss: 1.1929, Accuracy: 5613/10000 (56.1300%)

Current time: 1732615053.1154; Train Epoch: 3 [0/50000 (0%)]	Loss: 1.201991
Current time: 1732615058.0365; Train Epoch: 3 [25600/50000 (51%)]	Loss: 0.984025
Current time: 1732615064.4395; Test Epoch: 3, Test set: Average loss: 1.0471, Accuracy: 6372/10000 (63.7200%)

Current time: 1732615064.4660; Train Epoch: 4 [0/50000 (0%)]	Loss: 1.040236
Current time: 1732615069.3883; Train Epoch: 4 [25600/50000 (51%)]	Loss: 0.753797
Current time: 1732615075.7874; Test Epoch: 4, Test set: Average loss: 0.8325, Accuracy: 7139/10000 (71.3900%)

Current time: 1732615075.8140; Train Epoch: 5 [0/50000 (0%)]	Loss: 0.589611
Current time: 1732615080.7360; Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.761152
Current time: 1732615087.1364; Test Epoch: 5, Test set: Average loss: 0.8917, Accuracy: 7139/10000 (71.3900%)

Current time: 1732615087.1629; Train Epoch: 6 [0/50000 (0%)]	Loss: 0.559627
Current time: 1732615092.0851; Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.633205
Current time: 1732615098.4847; Test Epoch: 6, Test set: Average loss: 0.7604, Accuracy: 7492/10000 (74.9200%)

Current time: 1732615098.5112; Train Epoch: 7 [0/50000 (0%)]	Loss: 0.524038
Current time: 1732615103.4301; Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.605406
Current time: 1732615109.8236; Test Epoch: 7, Test set: Average loss: 0.8546, Accuracy: 7254/10000 (72.5400%)

Current time: 1732615109.8502; Train Epoch: 8 [0/50000 (0%)]	Loss: 0.432811
Current time: 1732615114.7743; Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.551206
Current time: 1732615121.1824; Test Epoch: 8, Test set: Average loss: 0.8004, Accuracy: 7618/10000 (76.1800%)

Current time: 1732615121.2090; Train Epoch: 9 [0/50000 (0%)]	Loss: 0.381817
Current time: 1732615126.1307; Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.574510
Current time: 1732615132.5323; Test Epoch: 9, Test set: Average loss: 0.8226, Accuracy: 7593/10000 (75.9300%)

Current time: 1732615132.5591; Train Epoch: 10 [0/50000 (0%)]	Loss: 0.124277
Current time: 1732615137.4785; Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.406409
Current time: 1732615143.8803; Test Epoch: 10, Test set: Average loss: 0.9111, Accuracy: 7516/10000 (75.1600%)

Current time: 1732615143.9068; Train Epoch: 11 [0/50000 (0%)]	Loss: 0.266931
Current time: 1732615148.8258; Train Epoch: 11 [25600/50000 (51%)]	Loss: 0.348439
Current time: 1732615155.2281; Test Epoch: 11, Test set: Average loss: 0.8588, Accuracy: 7568/10000 (75.6800%)

Current time: 1732615155.2547; Train Epoch: 12 [0/50000 (0%)]	Loss: 0.225013
Current time: 1732615160.1717; Train Epoch: 12 [25600/50000 (51%)]	Loss: 0.193020
Current time: 1732615166.5698; Test Epoch: 12, Test set: Average loss: 1.0098, Accuracy: 7494/10000 (74.9400%)

Current time: 1732615166.5963; Train Epoch: 13 [0/50000 (0%)]	Loss: 0.296886
Current time: 1732615171.5147; Train Epoch: 13 [25600/50000 (51%)]	Loss: 0.282503
Current time: 1732615177.9191; Test Epoch: 13, Test set: Average loss: 0.9688, Accuracy: 7566/10000 (75.6600%)

Current time: 1732615177.9458; Train Epoch: 14 [0/50000 (0%)]	Loss: 0.117060
Current time: 1732615182.8702; Train Epoch: 14 [25600/50000 (51%)]	Loss: 0.147374
Current time: 1732615189.2764; Test Epoch: 14, Test set: Average loss: 1.0346, Accuracy: 7618/10000 (76.1800%)

Current time: 1732615189.3030; Train Epoch: 15 [0/50000 (0%)]	Loss: 0.141543
Current time: 1732615194.2243; Train Epoch: 15 [25600/50000 (51%)]	Loss: 0.213078
Current time: 1732615200.6264; Test Epoch: 15, Test set: Average loss: 1.1812, Accuracy: 7534/10000 (75.3400%)

Current time: 1732615200.6529; Train Epoch: 16 [0/50000 (0%)]	Loss: 0.107486
Current time: 1732615205.5751; Train Epoch: 16 [25600/50000 (51%)]	Loss: 0.187165
Current time: 1732615211.9759; Test Epoch: 16, Test set: Average loss: 1.0476, Accuracy: 7484/10000 (74.8400%)

Current time: 1732615212.0026; Train Epoch: 17 [0/50000 (0%)]	Loss: 0.200170
Current time: 1732615216.9237; Train Epoch: 17 [25600/50000 (51%)]	Loss: 0.158545
Current time: 1732615223.3286; Test Epoch: 17, Test set: Average loss: 1.1841, Accuracy: 7627/10000 (76.2700%)

Current time: 1732615223.3550; Train Epoch: 18 [0/50000 (0%)]	Loss: 0.164631
Current time: 1732615228.2769; Train Epoch: 18 [25600/50000 (51%)]	Loss: 0.123497
Current time: 1732615234.7296; Test Epoch: 18, Test set: Average loss: 1.1529, Accuracy: 7580/10000 (75.8000%)

Current time: 1732615234.7561; Train Epoch: 19 [0/50000 (0%)]	Loss: 0.081150
Current time: 1732615239.6908; Train Epoch: 19 [25600/50000 (51%)]	Loss: 0.112434
Current time: 1732615246.1042; Test Epoch: 19, Test set: Average loss: 1.0364, Accuracy: 7605/10000 (76.0500%)

Current time: 1732615246.1307; Train Epoch: 20 [0/50000 (0%)]	Loss: 0.142495
Current time: 1732615251.0582; Train Epoch: 20 [25600/50000 (51%)]	Loss: 0.160989
Current time: 1732615257.4668; Test Epoch: 20, Test set: Average loss: 1.1639, Accuracy: 7630/10000 (76.3000%)

Current time: 1732615257.4933; Train Epoch: 21 [0/50000 (0%)]	Loss: 0.076485
Current time: 1732615262.4175; Train Epoch: 21 [25600/50000 (51%)]	Loss: 0.279832
Current time: 1732615268.8237; Test Epoch: 21, Test set: Average loss: 1.2394, Accuracy: 7632/10000 (76.3200%)

Current time: 1732615268.8503; Train Epoch: 22 [0/50000 (0%)]	Loss: 0.039759
Current time: 1732615273.7785; Train Epoch: 22 [25600/50000 (51%)]	Loss: 0.047274
Current time: 1732615280.1853; Test Epoch: 22, Test set: Average loss: 1.2308, Accuracy: 7669/10000 (76.6900%)

Current time: 1732615280.2118; Train Epoch: 23 [0/50000 (0%)]	Loss: 0.123380
Current time: 1732615285.1325; Train Epoch: 23 [25600/50000 (51%)]	Loss: 0.145116
Current time: 1732615291.5399; Test Epoch: 23, Test set: Average loss: 1.2950, Accuracy: 7598/10000 (75.9800%)

Current time: 1732615291.5664; Train Epoch: 24 [0/50000 (0%)]	Loss: 0.072040
Current time: 1732615296.4982; Train Epoch: 24 [25600/50000 (51%)]	Loss: 0.085737
Current time: 1732615302.9045; Test Epoch: 24, Test set: Average loss: 1.3689, Accuracy: 7560/10000 (75.6000%)

Current time: 1732615302.9310; Train Epoch: 25 [0/50000 (0%)]	Loss: 0.035381
Current time: 1732615307.8617; Train Epoch: 25 [25600/50000 (51%)]	Loss: 0.080791
Current time: 1732615314.2665; Test Epoch: 25, Test set: Average loss: 1.3125, Accuracy: 7585/10000 (75.8500%)

Current time: 1732615314.2934; Train Epoch: 26 [0/50000 (0%)]	Loss: 0.065840
Current time: 1732615319.2298; Train Epoch: 26 [25600/50000 (51%)]	Loss: 0.085776
Current time: 1732615325.6336; Test Epoch: 26, Test set: Average loss: 1.3329, Accuracy: 7607/10000 (76.0700%)

Current time: 1732615325.6602; Train Epoch: 27 [0/50000 (0%)]	Loss: 0.073142
Current time: 1732615330.5916; Train Epoch: 27 [25600/50000 (51%)]	Loss: 0.063895
Current time: 1732615337.0003; Test Epoch: 27, Test set: Average loss: 1.1973, Accuracy: 7517/10000 (75.1700%)

Current time: 1732615337.0268; Train Epoch: 28 [0/50000 (0%)]	Loss: 0.185187
Current time: 1732615341.9520; Train Epoch: 28 [25600/50000 (51%)]	Loss: 0.144753
Current time: 1732615348.3558; Test Epoch: 28, Test set: Average loss: 1.3464, Accuracy: 7681/10000 (76.8100%)

Current time: 1732615348.3826; Train Epoch: 29 [0/50000 (0%)]	Loss: 0.040233
Current time: 1732615353.3118; Train Epoch: 29 [25600/50000 (51%)]	Loss: 0.124520
Current time: 1732615359.7192; Test Epoch: 29, Test set: Average loss: 1.3083, Accuracy: 7601/10000 (76.0100%)

Current time: 1732615359.7457; Train Epoch: 30 [0/50000 (0%)]	Loss: 0.035350
Current time: 1732615364.6699; Train Epoch: 30 [25600/50000 (51%)]	Loss: 0.131890
Current time: 1732615371.0747; Test Epoch: 30, Test set: Average loss: 1.4087, Accuracy: 7625/10000 (76.2500%)

